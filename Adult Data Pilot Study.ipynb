{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1adc04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\sam\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sam\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: fairlearn in c:\\users\\sam\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn fairlearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cb66bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from fairlearn.metrics import MetricFrame, selection_rate, true_positive_rate, true_negative_rate, false_positive_rate, false_negative_rate\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "column_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "\n",
    "data = pd.read_csv(url, names=column_names, sep=',\\s', engine='python')\n",
    "\n",
    "# Preprocess the dataset\n",
    "# Drop rows with missing values\n",
    "data = data.replace('?', pd.NA).dropna()\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_columns = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\", \"income\"]\n",
    "data[categorical_columns] = data[categorical_columns].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(\"income\", axis=1)\n",
    "y = data[\"income\"]\n",
    "sensitive_feature = data[\"sex\"]  # Use sex as the sensitive feature\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(X, y, sensitive_feature, test_size=0.25, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c77b866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mitigated Model accuracy: 0.78\n",
      "Overall metrics for mitigated model:\n",
      "selection_rate         0.086063\n",
      "true_positive_rate     0.236828\n",
      "true_negative_rate     0.963970\n",
      "false_positive_rate    0.036030\n",
      "false_negative_rate    0.763172\n",
      "dtype: float64\n",
      "Metrics by group for mitigated model:\n",
      "        selection_rate  true_positive_rate  true_negative_rate  \\\n",
      "sex                                                              \n",
      "female        0.082286            0.336957            0.949795   \n",
      "male          0.087899            0.219588            0.972918   \n",
      "\n",
      "        false_positive_rate  false_negative_rate  \n",
      "sex                                               \n",
      "female             0.050205             0.663043  \n",
      "male               0.027082             0.780412  \n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model with fairness constraints\n",
    "estimator = LogisticRegression(max_iter=1000)\n",
    "constraint = DemographicParity()  # You can also use EqualizedOdds() for a different fairness constraint\n",
    "\n",
    "mitigator = ExponentiatedGradient(estimator, constraint)\n",
    "mitigator.fit(X_train, y_train, sensitive_features=sensitive_train)\n",
    "\n",
    "# Predict using the mitigated model\n",
    "y_pred_mitigated = mitigator.predict(X_test)\n",
    "\n",
    "# Evaluate the mitigated model\n",
    "accuracy_mitigated = accuracy_score(y_test, y_pred_mitigated)\n",
    "print(f\"Mitigated Model accuracy: {accuracy_mitigated:.2f}\")\n",
    "\n",
    "# Define a dictionary of metrics for the mitigated model\n",
    "metrics_mitigated = {\n",
    "    'selection_rate': selection_rate,\n",
    "    'true_positive_rate': true_positive_rate,\n",
    "    'true_negative_rate': true_negative_rate,\n",
    "    'false_positive_rate': false_positive_rate,\n",
    "    'false_negative_rate': false_negative_rate\n",
    "}\n",
    "\n",
    "# Create a MetricFrame to evaluate metrics by sensitive feature for the mitigated model\n",
    "metric_frame_mitigated = MetricFrame(\n",
    "    metrics=metrics_mitigated,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_mitigated,\n",
    "    sensitive_features=sensitive_test  # Already mapped to 'female' and 'male'\n",
    ")\n",
    "\n",
    "# Print the overall metrics for the mitigated model\n",
    "print(\"Overall metrics for mitigated model:\")\n",
    "print(metric_frame_mitigated.overall)\n",
    "\n",
    "# Mapping for display\n",
    "sex_display_mapping = {0: 'female', 1: 'male'}\n",
    "\n",
    "# Print the metrics by group for the mitigated model, with human-readable labels\n",
    "print(\"Metrics by group for mitigated model:\")\n",
    "metrics_by_group_mitigated = metric_frame_mitigated.by_group.rename(index=sex_display_mapping)\n",
    "print(metrics_by_group_mitigated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98f2cf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact: 0.58\n",
      "Bias Percentage: 42.23%\n"
     ]
    }
   ],
   "source": [
    "# Calculate Disparate Impact\n",
    "sr_by_group = metric_frame.by_group['selection_rate']\n",
    "disparate_impact = sr_by_group.min() / sr_by_group.max()\n",
    "bias_percentage = (1 - disparate_impact) * 100\n",
    "\n",
    "print(f\"Disparate Impact: {disparate_impact:.2f}\")\n",
    "print(f\"Bias Percentage: {bias_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e833c6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mitigated Model accuracy: 0.78\n",
      "Overall metrics for mitigated model:\n",
      "selection_rate         0.083676\n",
      "true_positive_rate     0.230974\n",
      "true_negative_rate     0.965207\n",
      "false_positive_rate    0.034793\n",
      "false_negative_rate    0.769026\n",
      "dtype: float64\n",
      "Metrics by group for mitigated model:\n",
      "        selection_rate  true_positive_rate  true_negative_rate  \\\n",
      "sex                                                              \n",
      "female        0.075801            0.307971            0.953446   \n",
      "male          0.087505            0.217717            0.972630   \n",
      "\n",
      "        false_positive_rate  false_negative_rate  \n",
      "sex                                               \n",
      "female             0.046554             0.692029  \n",
      "male               0.027370             0.782283  \n"
     ]
    }
   ],
   "source": [
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity, EqualizedOdds\n",
    "\n",
    "# Train a logistic regression model with fairness constraints\n",
    "estimator = LogisticRegression(max_iter=1000)\n",
    "constraint = DemographicParity()  # You can also use EqualizedOdds() for a different fairness constraint\n",
    "\n",
    "mitigator = ExponentiatedGradient(estimator, constraint)\n",
    "mitigator.fit(X_train, y_train, sensitive_features=sensitive_train)\n",
    "\n",
    "# Predict using the mitigated model\n",
    "y_pred_mitigated = mitigator.predict(X_test)\n",
    "\n",
    "# Evaluate the mitigated model\n",
    "accuracy_mitigated = accuracy_score(y_test, y_pred_mitigated)\n",
    "print(f\"Mitigated Model accuracy: {accuracy_mitigated:.2f}\")\n",
    "\n",
    "# Define a dictionary of metrics for the mitigated model\n",
    "metrics_mitigated = {\n",
    "    'selection_rate': selection_rate,\n",
    "    'true_positive_rate': true_positive_rate,\n",
    "    'true_negative_rate': true_negative_rate,\n",
    "    'false_positive_rate': false_positive_rate,\n",
    "    'false_negative_rate': false_negative_rate\n",
    "}\n",
    "\n",
    "# Create a MetricFrame to evaluate metrics by sensitive feature for the mitigated model\n",
    "metric_frame_mitigated = MetricFrame(\n",
    "    metrics=metrics_mitigated,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_mitigated,\n",
    "    sensitive_features=sensitive_test\n",
    ")\n",
    "\n",
    "# Print the overall metrics for the mitigated model\n",
    "print(\"Overall metrics for mitigated model:\")\n",
    "print(metric_frame_mitigated.overall)\n",
    "\n",
    "# Mapping for display\n",
    "sex_display_mapping = {0: 'female', 1: 'male'}\n",
    "\n",
    "# Print the metrics by group for the mitigated model, with human-readable labels\n",
    "print(\"Metrics by group for mitigated model:\")\n",
    "metrics_by_group_mitigated = metric_frame_mitigated.by_group.rename(index=sex_display_mapping)\n",
    "print(metrics_by_group_mitigated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f471b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mitigated Disparate Impact: 0.87\n",
      "Mitigated Bias Percentage: 12.72%\n"
     ]
    }
   ],
   "source": [
    "# Calculate Disparate Impact for the mitigated model\n",
    "sr_by_group_mitigated = metric_frame_mitigated.by_group['selection_rate']\n",
    "disparate_impact_mitigated = sr_by_group_mitigated.min() / sr_by_group_mitigated.max()\n",
    "bias_percentage_mitigated = (1 - disparate_impact_mitigated) * 100\n",
    "\n",
    "print(f\"Mitigated Disparate Impact: {disparate_impact_mitigated:.2f}\")\n",
    "print(f\"Mitigated Bias Percentage: {bias_percentage_mitigated:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f063812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'solver': 'liblinear'}\n",
      "Mitigated Model accuracy after tuning: 0.79\n",
      "Overall metrics for mitigated model after tuning:\n",
      "selection_rate         0.070548\n",
      "true_positive_rate     0.213944\n",
      "true_negative_rate     0.977040\n",
      "false_positive_rate    0.022960\n",
      "false_negative_rate    0.786056\n",
      "dtype: float64\n",
      "Metrics by group for mitigated model:\n",
      "        selection_rate  true_positive_rate  true_negative_rate  \\\n",
      "sex                                                              \n",
      "female        0.064045            0.278986            0.963031   \n",
      "male          0.073709            0.202745            0.985883   \n",
      "\n",
      "        false_positive_rate  false_negative_rate  \n",
      "sex                                               \n",
      "female             0.036969             0.721014  \n",
      "male               0.014117             0.797255  \n",
      "Mitigated Disparate Impact after tuning: 0.87\n",
      "Mitigated Bias Percentage after tuning: 13.11%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Train the best estimator with fairness constraints\n",
    "mitigator = ExponentiatedGradient(best_estimator, DemographicParity())\n",
    "mitigator.fit(X_train, y_train, sensitive_features=sensitive_train)\n",
    "\n",
    "# Predict using the mitigated model\n",
    "y_pred_mitigated = mitigator.predict(X_test)\n",
    "\n",
    "# Evaluate the mitigated model\n",
    "accuracy_mitigated = accuracy_score(y_test, y_pred_mitigated)\n",
    "print(f\"Mitigated Model accuracy after tuning: {accuracy_mitigated:.2f}\")\n",
    "\n",
    "# Define a dictionary of metrics for the mitigated model\n",
    "metrics_mitigated = {\n",
    "    'selection_rate': selection_rate,\n",
    "    'true_positive_rate': true_positive_rate,\n",
    "    'true_negative_rate': true_negative_rate,\n",
    "    'false_positive_rate': false_positive_rate,\n",
    "    'false_negative_rate': false_negative_rate\n",
    "}\n",
    "\n",
    "# Create a MetricFrame to evaluate metrics by sensitive feature for the mitigated model\n",
    "metric_frame_mitigated = MetricFrame(\n",
    "    metrics=metrics_mitigated,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_mitigated,\n",
    "    sensitive_features=sensitive_test\n",
    ")\n",
    "\n",
    "# Print the overall metrics for the mitigated model\n",
    "print(\"Overall metrics for mitigated model after tuning:\")\n",
    "print(metric_frame_mitigated.overall)\n",
    "\n",
    "# Mapping for display\n",
    "sex_display_mapping = {0: 'female', 1: 'male'}\n",
    "\n",
    "# Print the metrics by group for the mitigated model, with human-readable labels\n",
    "print(\"Metrics by group for mitigated model:\")\n",
    "metrics_by_group_mitigated = metric_frame_mitigated.by_group.rename(index=sex_display_mapping)\n",
    "print(metrics_by_group_mitigated)\n",
    "\n",
    "# Calculate Disparate Impact for the mitigated model\n",
    "sr_by_group_mitigated = metric_frame_mitigated.by_group['selection_rate']\n",
    "disparate_impact_mitigated = sr_by_group_mitigated.min() / sr_by_group_mitigated.max()\n",
    "bias_percentage_mitigated = (1 - disparate_impact_mitigated) * 100\n",
    "\n",
    "print(f\"Mitigated Disparate Impact after tuning: {disparate_impact_mitigated:.2f}\")\n",
    "print(f\"Mitigated Bias Percentage after tuning: {bias_percentage_mitigated:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95dab5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mitigated Model Precision: 0.74\n",
      "Mitigated Model Recall: 0.21\n",
      "Mitigated Model F1 Score: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Evaluate additional metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred_mitigated)\n",
    "recall = recall_score(y_test, y_pred_mitigated)\n",
    "f1 = f1_score(y_test, y_pred_mitigated)\n",
    "\n",
    "print(f\"Mitigated Model Precision: {precision:.2f}\")\n",
    "print(f\"Mitigated Model Recall: {recall:.2f}\")\n",
    "print(f\"Mitigated Model F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa42791c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalized Odds Model accuracy: 0.79\n",
      "Overall metrics for EqualizedOdds model:\n",
      "selection_rate         0.087522\n",
      "true_positive_rate     0.263970\n",
      "true_negative_rate     0.971035\n",
      "false_positive_rate    0.028965\n",
      "false_negative_rate    0.736030\n",
      "dtype: float64\n",
      "Metrics by group for mitigated model:\n",
      "        selection_rate  true_positive_rate  true_negative_rate  \\\n",
      "sex                                                              \n",
      "female        0.064045            0.278986            0.963031   \n",
      "male          0.073709            0.202745            0.985883   \n",
      "\n",
      "        false_positive_rate  false_negative_rate  \n",
      "sex                                               \n",
      "female             0.036969             0.721014  \n",
      "male               0.014117             0.797255  \n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model with EqualizedOdds constraint\n",
    "mitigator_equalized_odds = ExponentiatedGradient(best_estimator, EqualizedOdds())\n",
    "mitigator_equalized_odds.fit(X_train, y_train, sensitive_features=sensitive_train)\n",
    "\n",
    "# Predict using the mitigated model with EqualizedOdds\n",
    "y_pred_equalized_odds = mitigator_equalized_odds.predict(X_test)\n",
    "\n",
    "# Evaluate the model with EqualizedOdds constraint\n",
    "accuracy_equalized_odds = accuracy_score(y_test, y_pred_equalized_odds)\n",
    "print(f\"Equalized Odds Model accuracy: {accuracy_equalized_odds:.2f}\")\n",
    "\n",
    "# Create a MetricFrame to evaluate metrics by sensitive feature for the EqualizedOdds model\n",
    "metric_frame_equalized_odds = MetricFrame(\n",
    "    metrics=metrics_mitigated,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_equalized_odds,\n",
    "    sensitive_features=sensitive_test\n",
    ")\n",
    "\n",
    "# Print the overall metrics for the EqualizedOdds model\n",
    "print(\"Overall metrics for EqualizedOdds model:\")\n",
    "print(metric_frame_equalized_odds.overall)\n",
    "\n",
    "# Mapping for display\n",
    "sex_display_mapping = {0: 'female', 1: 'male'}\n",
    "\n",
    "# Print the metrics by group for the mitigated model, with human-readable labels\n",
    "print(\"Metrics by group for mitigated model:\")\n",
    "metrics_by_group_mitigated = metric_frame_mitigated.by_group.rename(index=sex_display_mapping)\n",
    "print(metrics_by_group_mitigated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab73b7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalized Odds Model accuracy: 0.79\n",
      "Overall metrics for EqualizedOdds model:\n",
      "selection_rate         0.087522\n",
      "true_positive_rate     0.263970\n",
      "true_negative_rate     0.971035\n",
      "false_positive_rate    0.028965\n",
      "false_negative_rate    0.736030\n",
      "dtype: float64\n",
      "Metrics by group for mitigated model:\n",
      "        selection_rate  true_positive_rate  true_negative_rate  \\\n",
      "sex                                                              \n",
      "female        0.064045            0.278986            0.963031   \n",
      "male          0.073709            0.202745            0.985883   \n",
      "\n",
      "        false_positive_rate  false_negative_rate  \n",
      "sex                                               \n",
      "female             0.036969             0.721014  \n",
      "male               0.014117             0.797255  \n",
      "Equalized Odds Model Disparate Impact: 0.57\n",
      "Equalized Odds Model Bias Percentage: 43.11%\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import MetricFrame, selection_rate\n",
    "\n",
    "# Define a dictionary of metrics for the mitigated model\n",
    "metrics_mitigated = {\n",
    "    'selection_rate': selection_rate,\n",
    "    'true_positive_rate': true_positive_rate,\n",
    "    'true_negative_rate': true_negative_rate,\n",
    "    'false_positive_rate': false_positive_rate,\n",
    "    'false_negative_rate': false_negative_rate\n",
    "}\n",
    "\n",
    "# Train a logistic regression model with EqualizedOdds constraint\n",
    "mitigator_equalized_odds = ExponentiatedGradient(best_estimator, EqualizedOdds())\n",
    "mitigator_equalized_odds.fit(X_train, y_train, sensitive_features=sensitive_train)\n",
    "\n",
    "# Predict using the mitigated model with EqualizedOdds\n",
    "y_pred_equalized_odds = mitigator_equalized_odds.predict(X_test)\n",
    "\n",
    "# Evaluate the model with EqualizedOdds constraint\n",
    "accuracy_equalized_odds = accuracy_score(y_test, y_pred_equalized_odds)\n",
    "print(f\"Equalized Odds Model accuracy: {accuracy_equalized_odds:.2f}\")\n",
    "\n",
    "# Create a MetricFrame to evaluate metrics by sensitive feature for the EqualizedOdds model\n",
    "metric_frame_equalized_odds = MetricFrame(\n",
    "    metrics=metrics_mitigated,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_equalized_odds,\n",
    "    sensitive_features=sensitive_test\n",
    ")\n",
    "\n",
    "# Print the overall metrics for the EqualizedOdds model\n",
    "print(\"Overall metrics for EqualizedOdds model:\")\n",
    "print(metric_frame_equalized_odds.overall)\n",
    "\n",
    "# Mapping for display\n",
    "sex_display_mapping = {0: 'female', 1: 'male'}\n",
    "\n",
    "# Print the metrics by group for the mitigated model, with human-readable labels\n",
    "print(\"Metrics by group for mitigated model:\")\n",
    "metrics_by_group_mitigated = metric_frame_mitigated.by_group.rename(index=sex_display_mapping)\n",
    "print(metrics_by_group_mitigated)\n",
    "\n",
    "# Calculate and Print Bias Metrics for the EqualizedOdds Model\n",
    "sr_by_group_equalized_odds = metric_frame_equalized_odds.by_group['selection_rate']\n",
    "disparate_impact_equalized_odds = sr_by_group_equalized_odds.min() / sr_by_group_equalized_odds.max()\n",
    "bias_percentage_equalized_odds = (1 - disparate_impact_equalized_odds) * 100\n",
    "\n",
    "print(f\"Equalized Odds Model Disparate Impact: {disparate_impact_equalized_odds:.2f}\")\n",
    "print(f\"Equalized Odds Model Bias Percentage: {bias_percentage_equalized_odds:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a68462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dynamic patch for np.PINF in fairlearn\n",
    "import fairlearn.reductions._exponentiated_gradient.exponentiated_gradient as eg\n",
    "if hasattr(np, 'PINF'):\n",
    "    np.PINF = np.inf  # Just in case, though it should already be removed\n",
    "eg.np.PINF = np.inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5c85d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
